{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9023f439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "titanic_train =pd.read_csv(\"/workspaces/titanic_dataset/train.csv\")\n",
    "titanic_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37cc2d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test = pd.read_csv(\"/workspaces/titanic_dataset/test.csv\")\n",
    "titanic_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b8efee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#titanic_train.info()\n",
    "titanic_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "131c7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb          # keep as module name\n",
    "import scipy.sparse as sp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read data\n",
    "titanic_train = pd.read_csv(\"/workspaces/titanic_dataset/train.csv\")\n",
    "titanic_test = pd.read_csv(\"/workspaces/titanic_dataset/test.csv\")\n",
    "\n",
    "# prepare features/target (drop obvious non-features)\n",
    "X = titanic_train.drop(columns=[\"Survived\", \"Name\", \"Ticket\", \"Cabin\", \"PassengerId\"], errors=\"ignore\")\n",
    "y = titanic_train[\"Survived\"]\n",
    "\n",
    "# split first to avoid leakage\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# feature lists (adjust if needed)\n",
    "num_cols = [\"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "pclass_col = [\"Pclass\"]               # ordinal\n",
    "cat_cols = [\"Sex\", \"Embarked\"]        # nominal -> one-hot\n",
    "\n",
    "# numeric pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# ordinal pipeline for Pclass\n",
    "pclass_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ord\", OrdinalEncoder(categories=[[1, 2, 3]]))\n",
    "])\n",
    "\n",
    "# categorical pipeline - use sparse_output=False (compatible with newer sklearn)\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"pclass\", pclass_pipeline, pclass_col),\n",
    "    (\"cat\", cat_pipeline, cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# pipeline for cross-validation (no early stopping here)\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\",\n",
    "                          n_estimators=200, learning_rate=0.1, random_state=42))\n",
    "])\n",
    "\n",
    "# cross-validate on training split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e90ee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [13:45:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [13:45:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [13:45:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [13:45:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [13:45:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy (5-fold) mean: 0.8020782034866543 std: 0.03711818992675806\n",
      "Validation accuracy (early-stopped): 0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb    # ensure module name is not shadowed\n",
    "import scipy.sparse as sp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# reload xgboost module to avoid accidental shadowing from earlier cells\n",
    "importlib.reload(xgb)\n",
    "\n",
    "# read data (if not already read)\n",
    "titanic_train = pd.read_csv(\"/workspaces/titanic_dataset/train.csv\")\n",
    "titanic_test  = pd.read_csv(\"/workspaces/titanic_dataset/test.csv\")\n",
    "\n",
    "# prepare features/target (drop non-features)\n",
    "X = titanic_train.drop(columns=[\"Survived\", \"Name\", \"Ticket\", \"Cabin\", \"PassengerId\"], errors=\"ignore\")\n",
    "y = titanic_train[\"Survived\"]\n",
    "\n",
    "# split first to avoid leakage\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# feature lists\n",
    "num_cols   = [\"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "pclass_col = [\"Pclass\"]            # ordinal\n",
    "cat_cols   = [\"Sex\", \"Embarked\"]   # nominal\n",
    "\n",
    "# pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "pclass_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ord\", OrdinalEncoder(categories=[[1, 2, 3]])),\n",
    "])\n",
    "\n",
    "# use sparse_output=False to be compatible with sklearn versions that expect it\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"pclass\", pclass_pipeline, pclass_col),\n",
    "    (\"cat\", cat_pipeline, cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# pipeline for CV (no early stopping here)\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\",\n",
    "                          n_estimators=200, learning_rate=0.1, random_state=42)),\n",
    "])\n",
    "\n",
    "# cross-validate on training split\n",
    "cv_scores = cross_val_score(full_pipeline, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"CV accuracy (5-fold) mean:\", cv_scores.mean(), \"std:\", cv_scores.std())\n",
    "\n",
    "# fit preprocessor and prepare arrays for xgboost native API (DMatrix)\n",
    "X_train_t = preprocessor.fit_transform(X_train)\n",
    "X_val_t   = preprocessor.transform(X_val)\n",
    "\n",
    "# convert sparse -> dense if necessary (DMatrix prefers dense numpy)\n",
    "if sp.issparse(X_train_t):\n",
    "    X_train_t = X_train_t.toarray()\n",
    "if sp.issparse(X_val_t):\n",
    "    X_val_t = X_val_t.toarray()\n",
    "\n",
    "# ensure numpy dtype\n",
    "X_train_t = np.asarray(X_train_t, dtype=np.float32)\n",
    "X_val_t   = np.asarray(X_val_t, dtype=np.float32)\n",
    "y_train_a = y_train.to_numpy()\n",
    "y_val_a   = y_val.to_numpy()\n",
    "\n",
    "# use native xgboost.train for early stopping (avoids wrapper inconsistencies)\n",
    "dtrain = xgb.DMatrix(X_train_t, label=y_train_a)\n",
    "dval   = xgb.DMatrix(X_val_t, label=y_val_a)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"eta\": 0.05,   # learning_rate\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dval, \"validation\")],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# predict using best iteration (handle API differences)\n",
    "best_it = getattr(bst, \"best_iteration\", None)\n",
    "try:\n",
    "    if best_it is not None:\n",
    "        probs = bst.predict(dval, ntree_limit=best_it + 1)\n",
    "    else:\n",
    "        probs = bst.predict(dval)\n",
    "except TypeError:\n",
    "    # newer xgboost may use iteration_range\n",
    "    if best_it is not None:\n",
    "        probs = bst.predict(dval, iteration_range=(0, best_it + 1))\n",
    "    else:\n",
    "        probs = bst.predict(dval)\n",
    "\n",
    "val_preds = (probs > 0.5).astype(int)\n",
    "print(\"Validation accuracy (early-stopped):\", accuracy_score(y_val_a, val_preds))\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562c8c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No evals_result available to plot training history.\n",
      "ROC plot failed: name 'y_val_a' is not defined\n",
      "Confusion matrix failed: name 'y_val_a' is not defined\n",
      "Feature importance plotting failed: name 'num_cols' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1) training/validation logloss over boosting rounds (if available)\n",
    "evals_result = {}\n",
    "try:\n",
    "    evals_result = bst.evals_result()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if evals_result:\n",
    "    # find first valid eval set and metric\n",
    "    plt.figure(figsize=(6,4))\n",
    "    # evals_result structure: { \"validation\": {\"logloss\": [...], ...}, ... }\n",
    "    for data_name, metrics in evals_result.items():\n",
    "        for metric_name, values in metrics.items():\n",
    "            plt.plot(values, label=f\"{data_name}-{metric_name}\")\n",
    "    plt.xlabel(\"Boosting round\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.title(\"Training/Validation metrics per boosting round\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No evals_result available to plot training history.\")\n",
    "\n",
    "# 2) ROC curve + AUC\n",
    "try:\n",
    "    fpr, tpr, _ = roc_curve(y_val_a, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC curve (validation)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"ROC plot failed:\", e)\n",
    "\n",
    "# 3) Confusion matrix + classification report\n",
    "try:\n",
    "    cm = confusion_matrix(y_val_a, val_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (validation)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Classification report (validation):\")\n",
    "    print(classification_report(y_val_a, val_preds, digits=4))\n",
    "except Exception as e:\n",
    "    print(\"Confusion matrix failed:\", e)\n",
    "\n",
    "# 4) Feature importances mapped to preprocessor output feature names\n",
    "try:\n",
    "    # build feature names from fitted preprocessor\n",
    "    feature_names = []\n",
    "    # numeric\n",
    "    feature_names.extend(num_cols)\n",
    "    # ordinal\n",
    "    feature_names.extend(pclass_col)\n",
    "    # one-hot: get fitted onehot encoder categories\n",
    "    onehot = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "    cat_input_col = cat_cols[0] if len(cat_cols) == 1 else None\n",
    "    # build names for all categorical columns in cat_cols\n",
    "    # We assume OneHotEncoder was applied to all cat_cols together\n",
    "    if hasattr(onehot, \"categories_\"):\n",
    "        cat_feature_names = []\n",
    "        # If multiple categorical input columns, categories_ is list in same order\n",
    "        for col, cats in zip(cat_cols, onehot.categories_):\n",
    "            cat_feature_names.extend([f\"{col}_{str(c)}\" for c in cats])\n",
    "        feature_names.extend(cat_feature_names)\n",
    "    # get importance dict from booster\n",
    "    imp = bst.get_score(importance_type=\"gain\")  # fallback weight/cover if needed\n",
    "    if not imp:\n",
    "        imp = bst.get_score(importance_type=\"weight\")\n",
    "    # convert keys 'f0'.. to indices and map to names\n",
    "    imp_map = {}\n",
    "    for k, v in imp.items():\n",
    "        idx = int(k.lstrip(\"f\"))\n",
    "        name = feature_names[idx] if idx < len(feature_names) else f\"f{idx}\"\n",
    "        imp_map[name] = v\n",
    "    # prepare dataframe for plotting\n",
    "    import pandas as pd\n",
    "    fi = pd.DataFrame.from_dict(imp_map, orient=\"index\", columns=[\"importance\"])\n",
    "    fi = fi.sort_values(\"importance\", ascending=True)\n",
    "    if not fi.empty:\n",
    "        plt.figure(figsize=(6, max(4, 0.25 * len(fi))))\n",
    "        fi[\"importance\"].plot(kind=\"barh\", color=\"C1\")\n",
    "        plt.title(\"Feature importance (gain)\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No feature importances available from booster.\")\n",
    "except Exception as e:\n",
    "    print(\"Feature importance plotting failed:\", e)\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
